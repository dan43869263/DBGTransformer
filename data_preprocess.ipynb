{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr=pd.read_csv('20220308_monthlybond_sample.csv') #bond attributes\n",
    "net=pd.read_csv('20220212_individual_holding_sample.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SORTED DATAFRAME\n"
     ]
    }
   ],
   "source": [
    "#preprocess for net\n",
    "#step1 sort the cusip and fundid month\n",
    "print('SORTED DATAFRAME')\n",
    "net=net.sort_values(by = ['fundid', 'cusip','yq'], ascending = [True, True,True])\n",
    "\n",
    "#calculate fund attributes (not use in this paper)\n",
    "net['meanpar']=net.groupby(['fundid','yq'])['paramt'].transform(np.mean)\n",
    "net['maxpar']=net.groupby(['fundid','yq'])['paramt'].transform(np.max)\n",
    "net['minpar']=net.groupby(['fundid','yq'])['paramt'].transform(np.min)\n",
    "net['stdpar']=net.groupby(['fundid','yq'])['paramt'].transform(np.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fund attribute (not use in this paper)\n",
    "fund_attr=net[['fundid','yq','holdingbond','totalpar','matchp','meanpar','maxpar','minpar','stdpar']]\n",
    "#drop duplicates from DataFrame\n",
    "fund_attr1 = fund_attr.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SORTED DATAFRAME\n"
     ]
    }
   ],
   "source": [
    "######try to calculate the return\n",
    "#step1 sort the cusip and month\n",
    "print('SORTED DATAFRAME')\n",
    "attr=attr.sort_values(by = ['cusip', 'month'], ascending = [True, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 2 in order to calculate the time gap, make the attr['month'] with data type datetime\n",
    "attr['month_datetime'] = pd.to_datetime(attr['month'], format='%Y%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_gap_value = attr.groupby(\"cusip\")[\"month_datetime\"].apply(\n",
    "    lambda x: (x-x.shift(1))/np.timedelta64(1, 'M')) \n",
    "attr['month_gap']=np.round(month_gap_value,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    6132.000000\n",
       "mean      107.410591\n",
       "std        16.593793\n",
       "min         7.125000\n",
       "25%       100.390000\n",
       "50%       107.426600\n",
       "75%       114.815500\n",
       "max       164.726000\n",
       "Name: p, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#step 3 check the price\n",
    "attr['p'].describe()\n",
    "#You might consider to remove all observations for a given bond if its average price is <30% (p<30) \n",
    "# or its average price is >150% (p>150). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = attr.groupby('cusip').filter(lambda g: g['p'].mean() < 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    6132.000000\n",
       "mean      107.410591\n",
       "std        16.593793\n",
       "min         7.125000\n",
       "25%       100.390000\n",
       "50%       107.426600\n",
       "75%       114.815500\n",
       "max       164.726000\n",
       "Name: p, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['p'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.groupby('cusip').filter(lambda g: g['p'].mean() > 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    6132.000000\n",
       "mean      107.410591\n",
       "std        16.593793\n",
       "min         7.125000\n",
       "25%       100.390000\n",
       "50%       107.426600\n",
       "75%       114.815500\n",
       "max       164.726000\n",
       "Name: p, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['p'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.586737500000005\n",
      "159.3366048\n"
     ]
    }
   ],
   "source": [
    "q1=df2['p'].quantile(0.0075)\n",
    "print(q1)\n",
    "q2=df2['p'].quantile(0.9972)\n",
    "print(q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['p'].clip(lower=df2['p'].quantile(0.0075), upper=df2['p'].quantile(0.9972), axis=0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    6132.000000\n",
       "mean      107.532865\n",
       "std        15.977146\n",
       "min        43.586738\n",
       "25%       100.390000\n",
       "50%       107.426600\n",
       "75%       114.815500\n",
       "max       159.336605\n",
       "Name: p, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['p'].describe() #for price min 30 max 150 mean 102.58"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5819.000000\n",
       "mean        5.943992\n",
       "std         6.753819\n",
       "min         0.367411\n",
       "25%         4.431515\n",
       "50%         5.497463\n",
       "75%         6.899289\n",
       "max       453.709122\n",
       "Name: yd, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#step 4 check the yield\n",
    "df2['yd'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.343087599999976"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For bond yields (yd) which is in %, there will be outliers on one large side. \n",
    "# You might treat yd as missing if yd>30 (about 0.5%) or yd>20 (about 1%). \n",
    "q1=df2['yd'].quantile(0.991)\n",
    "q1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['yd'].clip(upper=df2['yd'].quantile(0.991), axis=0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5819.000000\n",
       "mean        5.780807\n",
       "std         2.680529\n",
       "min         0.367411\n",
       "25%         4.431515\n",
       "50%         5.497463\n",
       "75%         6.899289\n",
       "max        17.343088\n",
       "Name: yd, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['yd'].describe() #for yiled, min 0 max 28.2 mean 5.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 5 calculate the return\n",
    "df2['return_term']=df2['p']*10+df2['ai']+df2['cpn']\n",
    "\n",
    "#for each bond calculate the return\n",
    "return_value = df2.groupby(\"cusip\")[\"return_term\"].apply(\n",
    "    lambda x: (x-x.shift(1))/x.shift(1)) \n",
    "df2['return']=return_value\n",
    "\n",
    "#devided by the month_gap\n",
    "df2['return']=df2['return']/df2['month_gap']\n",
    "\n",
    "# if the month gap large than 12, set the return as nan\n",
    "df2.loc[df2['month_gap']>12,'return']=np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    6074.000000\n",
       "mean        0.002096\n",
       "std         0.046677\n",
       "min        -0.422279\n",
       "25%        -0.014574\n",
       "50%         0.002225\n",
       "75%         0.016765\n",
       "max         0.880855\n",
       "Name: return, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['return'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.13065298023989488\n",
      "0.19204515438235426\n"
     ]
    }
   ],
   "source": [
    "#winsorize on the return\n",
    "q1=df2['return'].quantile(0.01)\n",
    "print(q1)\n",
    "q2=df2['return'].quantile(0.995)\n",
    "print(q2)\n",
    "\n",
    "df2['return'].clip(lower=df2['return'].quantile(0.01), upper=df2['return'].quantile(0.995), axis=0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    6074.000000\n",
       "mean        0.002081\n",
       "std         0.039048\n",
       "min        -0.130653\n",
       "25%        -0.014574\n",
       "50%         0.002225\n",
       "75%         0.016765\n",
       "max         0.192045\n",
       "Name: return, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['return'].describe() #min -0.122 max 0.198 mean 0.00188"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr=df2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data preprocess\n",
    "#net: 1. remove the bond and fund with only a few records\n",
    "net=net.groupby('cusip').filter(lambda x: x['fundid'].nunique() > 20)\n",
    "#net=net.groupby('fundid').filter(lambda x: x['cusip'].nunique() > 20)\n",
    "net=net[['cusip','fundid','yq','paramt']]\n",
    "\n",
    "net_bond=net['cusip'].unique()\n",
    "net_yq=net['yq'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attr\n",
    "#1 for all cusip fill the month\n",
    "df1=pd.DataFrame(data=product(attr['cusip'].unique(), np.sort(attr['month'].unique())))\n",
    "df1.columns=['cusip','month']\n",
    "attr=pd.merge(df1, attr, how='left', on=['cusip','month'])\n",
    "attr=attr.sort_values(['cusip','month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attr 3 fill the missing in the rating\n",
    "#fill the missing by the most recent rating \n",
    "attr['rat_moodys']=attr.groupby('cusip')['rat_moodys'].apply(lambda x: x.fillna(method='ffill'))\n",
    "attr['rat_low']=attr.groupby('cusip')['rat_low'].apply(lambda x: x.fillna(method='ffill'))\n",
    "attr['rat_med']=attr.groupby('cusip')['rat_med'].apply(lambda x: x.fillna(method='ffill'))\n",
    "attr['rat_last']=attr.groupby('cusip')['rat_last'].apply(lambda x: x.fillna(method='ffill'))\n",
    "# fill the missing in the ttm\n",
    "attr['ttm']=attr.groupby('cusip')['ttm'].apply(lambda x: x.fillna(method='ffill'))\n",
    "# fill the missing in the cpn\n",
    "attr['cpn']=attr.groupby('cusip')['cpn'].apply(lambda x: x.fillna(method='ffill'))\n",
    "#fill the missing in ai\n",
    "attr['ai']=attr.groupby('cusip')['ai'].apply(lambda x: x.fillna(method='ffill'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attr: 2.select the bond and yq in the net dataset\n",
    "attr=attr[attr['cusip'].isin(net_bond)] #bond in net\n",
    "\n",
    "#yq in net\n",
    "#transfer the month to yq in attr data\n",
    "\n",
    "#1match the month in bond attribute with the quarter in net\n",
    "attr['yy']=attr['month']//100*100\n",
    "attr['mm']=attr['month']%100\n",
    "attr['yq']=1\n",
    "attr.loc[attr['mm'].isin((1,2,3)),'yq']=attr[attr['mm'].isin((1,2,3))]['yy'].values+1\n",
    "attr.loc[attr['mm'].isin((4,5,6)),'yq']=attr[attr['mm'].isin((4,5,6))]['yy'].values+2\n",
    "attr.loc[attr['mm'].isin((7,8,9)),'yq']=attr[attr['mm'].isin((7,8,9))]['yy'].values+3\n",
    "attr.loc[attr['mm'].isin((10,11,12)),'yq']=attr[attr['mm'].isin((10,11,12))]['yy'].values+4\n",
    "#select yq in the net dataset\n",
    "attr=attr[attr['yq'].isin(net_yq)] #bond in net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bonds will be removed\n"
     ]
    }
   ],
   "source": [
    "#attr 5 keep the bond with at least 10 months records of 7 attributes and targets\n",
    "select_attr=['p', 'yd', 'return','rat_moodys', 'rat_low', 'rat_med','rat_last','ttm','cpn','ai']\n",
    "remove_bond=np.array([])\n",
    "for var in select_attr:\n",
    "    remove_item=attr['cusip'].unique()[attr.groupby('cusip')[var].count()<10]\n",
    "    remove_bond=np.append(remove_bond,remove_item)\n",
    "\n",
    "remove_bond=np.unique(remove_bond)\n",
    "print(len(remove_bond),'bonds will be removed')\n",
    "\n",
    "attr=attr[~attr['cusip'].isin(remove_bond)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of bond in bond attributes 54\n",
      "number of bond in bond fund bipartite graph 55\n",
      "54\n",
      "number of yq in bond attributes 58\n",
      "number of yq in bond fund bipartite graph 73\n",
      "58\n"
     ]
    }
   ],
   "source": [
    "#merge\n",
    "#1.select common bond and yq in attr and net\n",
    "#common bond\n",
    "print('number of bond in bond attributes',len(attr['cusip'].unique()))\n",
    "print('number of bond in bond fund bipartite graph',len(net['cusip'].unique()))\n",
    "common_bond=np.intersect1d(attr['cusip'].unique(),net['cusip'].unique())\n",
    "print(len(common_bond))\n",
    "\n",
    "#common quarter\n",
    "print('number of yq in bond attributes',len(attr['yq'].unique()))\n",
    "print('number of yq in bond fund bipartite graph',len(net['yq'].unique()))\n",
    "common_yq=np.intersect1d(attr['yq'].unique(),net['yq'].unique())\n",
    "print(len(common_yq))\n",
    "common_yq=np.sort(common_yq)\n",
    "#2. decide the sequence and net tensor\n",
    "#3.decide the sequence and net tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select common in the bond attribute dataset\n",
    "attr=attr[attr['cusip'].isin(common_bond) & attr['yq'].isin(common_yq)]\n",
    "attr=attr[['cusip','month','yq','rat_moodys','rat_low','rat_med','rat_last','ttm','cpn','ai','p','yd','return']]\n",
    "\n",
    "#select common bond and common yq in net\n",
    "net=net[['cusip','yq','fundid','paramt']]\n",
    "net=net[net['cusip'].isin(common_bond) & net['yq'].isin(common_yq)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the fund_attr\n",
    "#attr\n",
    "#1 for all cusip fill the month\n",
    "#common_fund=net['fundid'].unique()\n",
    "df1=pd.DataFrame(data=product(fund_attr1['fundid'].unique(), np.sort(fund_attr1['yq'].unique())))\n",
    "df1.columns=['fundid','yq']\n",
    "df1.shape\n",
    "fund_attr2=pd.merge(df1, fund_attr1, how='left', on=['fundid','yq'])\n",
    "fund_attr2=fund_attr2.sort_values(['fundid','yq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "fund_attr=fund_attr2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attr 3 fill the missing in the rating\n",
    "#fill the missing by the most recent rating \n",
    "fund_attr['holdingbond']=fund_attr.groupby('fundid')['holdingbond'].apply(lambda x: x.fillna(method='ffill'))\n",
    "fund_attr['totalpar']=fund_attr.groupby('fundid')['totalpar'].apply(lambda x: x.fillna(method='ffill'))\n",
    "fund_attr['matchp']=fund_attr.groupby('fundid')['matchp'].apply(lambda x: x.fillna(method='ffill'))\n",
    "fund_attr['meanpar']=fund_attr.groupby('fundid')['meanpar'].apply(lambda x: x.fillna(method='ffill'))\n",
    "fund_attr['maxpar']=fund_attr.groupby('fundid')['maxpar'].apply(lambda x: x.fillna(method='ffill'))\n",
    "fund_attr['minpar']=fund_attr.groupby('fundid')['minpar'].apply(lambda x: x.fillna(method='ffill'))\n",
    "fund_attr['stdpar']=fund_attr.groupby('fundid')['stdpar'].apply(lambda x: x.fillna(method='ffill'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the fund_attr\n",
    "#attr\n",
    "#1 for all cusip fill the month\n",
    "common_fund=net['fundid'].unique()\n",
    "df1=pd.DataFrame(data=product(common_fund, common_yq))\n",
    "df1.columns=['fundid','yq']\n",
    "fund_attr=df1.merge(fund_attr, how='left', on=['fundid','yq'])\n",
    "#fund_attr=fund_attr.sort_values(['fundid','yq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr.to_csv('attr_clean_new.csv')\n",
    "net.to_csv('net_clean_new.csv')\n",
    "fund_attr.to_csv('fund_clean_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b78d160af20a006c42127553cfbd26ae539fee0e8b16001f9071993416b33049"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
